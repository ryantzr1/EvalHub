# EvalHub ðŸš€

**Evaluate your machine learning models against academic benchmarks with just a few clicks!**

## Description

EvalHub is a platform designed to help you discover and review evaluation metrics for your machine learning models. Explore a variety of metrics here and then head over to the [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/main) repository by EleutherAI to evaluate your models.

## Features

- **Metric Discovery**: Search and filter through a comprehensive list of evaluation metrics.
- **Detailed Information**: View detailed descriptions, GitHub links, and paper links for each metric.
- **Categorization**: Metrics are organized into categories for easy navigation.
- **User Reviews**: Coming soon - see reviews and ratings from other researchers.

## Roadmap

- **Review System**: Implement a review system for users to rate and comment on metrics.
- **Detailed Analysis**: Provide in-depth analysis and comparisons of different metrics.
- **Additional Features**: More features to be added based on user feedback and needs.

## Contributing

Disclaimer: This platform is a work in progress. Contributions are welcome!
Feature Requests: If you have an idea for a new feature, please open an issue to discuss it before starting development.
